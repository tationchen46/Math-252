# Get unique values of STATUS if it's not a factor
unique_values <- unique(yrs_above$STATUS)
# Print the unique values
print(unique_values)
# Print the number of unique values
print(paste("Number of unique values in STATUS:", length(unique_values)))
#so total should have 8 cluster
#Return False means no missing value
#remove the "" value in the cells
yrs_above <- yrs_above[yrs_above$OCCUPATION_TYPE != "", ]
#married<-married %>% select(-ID, -NAME_FAMILY_STATUS,-STATUS)
library(dplyr)
# Check if all columns exist
if (all(c("ID", "DAYS_BIRTH", "STATUS") %in% colnames(yrs_above))) {
# If all columns exist, remove them using dplyr's select
yrs_above <- dplyr::select(yrs_above, -ID, -DAYS_BIRTH, -STATUS)
} else {
# If not all columns exist, take an alternative action
print("One or more specified columns do not exist in the dataframe.")
}
data_matrix8 <- as.data.frame(yrs_above)
#Step 3: Extract the significant variable
# Assuming data_matrix8 is your dataset
column_lengths <- sapply(data_matrix8, length)
# View the lengths
print(column_lengths)
# Check if all columns have the same length
all_equal <- all(column_lengths == column_lengths[1])
if (all_equal) {
print("All columns have the same length.")
} else {
print("Not all columns have the same length.")
}
# Assuming data_matrix1 is already loaded in your R environment
library(FactoMineR)
# Performing FAMD
famd_result <- FAMD(data_matrix8, graph = FALSE)
# Selecting top contributing variables for the first ten principal component
top_variables_dim2 <- sort(famd_result$var$contrib[, "Dim.1"], decreasing = TRUE)[1:10]
# for the first ten principal component name
top_var_df3 <- as.data.frame(top_variables_dim2)
top_var_df3$Variable <- rownames(top_var_df3)
subset_data_matrix8 <- data_matrix8[, top_var_df3$Variable]
#View(subset_data_matrix8)
# Recalculate the distance matrix
library(gower)
# Convert character columns to factors or numerics
if (exists("subset_data_matrix8")) {
for (col in colnames(subset_data_matrix8)) {
if (is.character(subset_data_matrix8[[col]])) {
subset_data_matrix8[[col]] <- as.factor(subset_data_matrix8[[col]])
}
}
} else {
print("subset_data_matrix8 is not a valid data frame.")
}
dist_matrix = daisy(subset_data_matrix8,metric = 'gower')
# Hierarchical clustering
hc <- hclust(dist_matrix, method = "complete")  # You can try different methods like "average", "single", etc.
print(hc)
plot(hc)
# Cutting the dendrogram to form clusters
cutree_hc <- cutree(hc, k = 8) # for example, 8 clusters
# Silhouette analysis
silhouette_score <- silhouette(cutree_hc, daisy(subset_data_matrix8,metric = 'gower'))
plot(silhouette_score,col="blue")
#cophenetic
copheneticA<-cophenetic(hc)
cor(copheneticA,dist_matrix)
#using wss
fviz_nbclust(subset_data_matrix2,hcut,method = c("wss"))
#using wss
fviz_nbclust(subset_data_matrix8,hcut,method = c("wss"))
#using silhouette
fviz_nbclust(subset_data_matrix8,hcut,method = c("silhouette"))
#dunn index
library(fpc)
dunn_index <- cluster.stats(dist_matrix, cutree_hc)$dunn
print(dunn_index)
#Check is NA value in sub_data4
any(is.na(yrs_below))
# we want to know how many level does categorical variable status have.
# Get unique values of STATUS if it's not a factor
unique_values <- unique(yrs_below$STATUS)
# Print the unique values
print(unique_values)
# Print the number of unique values
print(paste("Number of unique values in STATUS:", length(unique_values)))
#so total should have 4 cluster
#Return False means no missing value
#remove the "" value in the cells
yrs_below <- yrs_below[yrs_below$OCCUPATION_TYPE != "", ]
#married<-married %>% select(-ID, -NAME_FAMILY_STATUS,-STATUS)
library(dplyr)
# Check if all columns exist
if (all(c("ID", "DAYS_BIRTH", "STATUS") %in% colnames(yrs_below))) {
# If all columns exist, remove them using dplyr's select
yrs_below <- dplyr::select(yrs_below, -ID, -DAYS_BIRTH, -STATUS)
} else {
# If not all columns exist, take an alternative action
print("One or more specified columns do not exist in the dataframe.")
}
data_matrix9 <- as.data.frame(yrs_below)
#Step 3: Extract the significant variable
# Assuming data_matrix9 is your dataset
column_lengths <- sapply(data_matrix9, length)
# View the lengths
print(column_lengths)
# Check if all columns have the same length
all_equal <- all(column_lengths == column_lengths[1])
if (all_equal) {
print("All columns have the same length.")
} else {
print("Not all columns have the same length.")
}
# Assuming data_matrix1 is already loaded in your R environment
library(FactoMineR)
# Performing FAMD
famd_result <- FAMD(data_matrix9, graph = FALSE)
# Selecting top contributing variables for the first ten principal component
top_variables_dim2 <- sort(famd_result$var$contrib[, "Dim.1"], decreasing = TRUE)[1:10]
# for the first ten principal component name
top_var_df3 <- as.data.frame(top_variables_dim2)
top_var_df3$Variable <- rownames(top_var_df3)
subset_data_matrix9 <- data_matrix9[, top_var_df3$Variable]
#View(subset_data_matrix9)
# Recalculate the distance matrix
library(gower)
# Convert character columns to factors or numerics
if (exists("subset_data_matrix9")) {
for (col in colnames(subset_data_matrix9)) {
if (is.character(subset_data_matrix9[[col]])) {
subset_data_matrix9[[col]] <- as.factor(subset_data_matrix9[[col]])
}
}
} else {
print("subset_data_matrix9 is not a valid data frame.")
}
dist_matrix = daisy(subset_data_matrix9,metric = 'gower')
# Hierarchical clustering
hc <- hclust(dist_matrix, method = "complete")  # You can try different methods like "average", "single", etc.
print(hc)
plot(hc)
# Cutting the dendrogram to form clusters
cutree_hc <- cutree(hc, k = 4) # for example, 4 clusters
# Silhouette analysis
silhouette_score <- silhouette(cutree_hc, daisy(subset_data_matrix9,metric = 'gower'))
plot(silhouette_score,col="blue")
#cophenetic
copheneticA<-cophenetic(hc)
cor(copheneticA,dist_matrix)
#using wss
fviz_nbclust(subset_data_matrix2,hcut,method = c("wss"))
#using silhouette
fviz_nbclust(subset_data_matrix2,hcut,method = c("silhouette"))
#using wss
fviz_nbclust(subset_data_matrix9,hcut,method = c("wss"))
#using silhouette
fviz_nbclust(subset_data_matrix9,hcut,method = c("silhouette"))
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix9),4)
#View(subset_data_matrix4)
# Perform k-proto clustering on the cleaned matrix
#clusters <- kmodes(subset_data_matrix6,try_clusters)
#clusters$cluster
km=kproto(subset_data_matrix9,try_clusters)
km$cluster
#Check is NA value in sub_data4
any(is.na(single))
# we want to know how many level does categorical variable status have.
# Get unique values of STATUS if it's not a factor
unique_values <- unique(single$STATUS)
# Print the unique values
print(unique_values)
# Print the number of unique values
print(paste("Number of unique values in STATUS:", length(unique_values)))
#so total should have 3 cluster
#Return False means no missing value
#remove the "" value in the cells
single <- single[single$OCCUPATION_TYPE != "", ]
#married<-married %>% select(-ID, -NAME_FAMILY_STATUS,-STATUS)
library(dplyr)
# Check if all columns exist
if (all(c("ID", "NAME_FAMILY_STATUS", "STATUS") %in% colnames(single))) {
# If all columns exist, remove them using dplyr's select
single <- dplyr::select(single, -ID, -NAME_FAMILY_STATUS, -STATUS)
} else {
# If not all columns exist, take an alternative action
print("One or more specified columns do not exist in the dataframe.")
}
data_matrix10 <- as.data.frame(single)
#Step 3: Extract the significant variable
# Assuming data_matrix9 is your dataset
column_lengths <- sapply(data_matrix10, length)
# View the lengths
print(column_lengths)
# Check if all columns have the same length
all_equal <- all(column_lengths == column_lengths[1])
if (all_equal) {
print("All columns have the same length.")
} else {
print("Not all columns have the same length.")
}
# Assuming data_matrix1 is already loaded in your R environment
library(FactoMineR)
# Performing FAMD
famd_result <- FAMD(data_matrix10, graph = FALSE)
# Selecting top contributing variables for the first ten principal component
top_variables_dim2 <- sort(famd_result$var$contrib[, "Dim.1"], decreasing = TRUE)[1:10]
# for the first ten principal component name
top_var_df3 <- as.data.frame(top_variables_dim2)
top_var_df3$Variable <- rownames(top_var_df3)
subset_data_matrix10 <- data_matrix10[, top_var_df3$Variable]
#View(subset_data_matrix10)
# Recalculate the distance matrix
library(gower)
# Convert character columns to factors or numerics
if (exists("subset_data_matrix10")) {
for (col in colnames(subset_data_matrix10)) {
if (is.character(subset_data_matrix10[[col]])) {
subset_data_matrix10[[col]] <- as.factor(subset_data_matrix10[[col]])
}
}
} else {
print("subset_data_matrix9 is not a valid data frame.")
}
dist_matrix = daisy(subset_data_matrix10,metric = 'gower')
# Hierarchical clustering
hc <- hclust(dist_matrix, method = "complete")  # You can try different methods like "average", "single", etc.
print(hc)
plot(hc)
# Cutting the dendrogram to form clusters
cutree_hc <- cutree(hc, k = 3) # for example, 3 clusters
# Silhouette analysis
silhouette_score <- silhouette(cutree_hc, daisy(subset_data_matrix10,metric = 'gower'))
plot(silhouette_score,col="blue")
#cophenetic
copheneticA<-cophenetic(hc)
cor(copheneticA,dist_matrix)
#using wss
fviz_nbclust(subset_data_matrix2,hcut,method = c("wss"))
#using wss
fviz_nbclust(subset_data_matrix10,hcut,method = c("wss"))
#using silhouette
fviz_nbclust(subset_data_matrix10,hcut,method = c("silhouette"))
#dunn index
library(fpc)
dunn_index <- cluster.stats(dist_matrix, cutree_hc)$dunn
print(dunn_index)
#kprototype
library(klaR)
library(clustMixType)
library(factoextra)
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix4), 8)
# Perform k-proto clustering on the cleaned matrix
# Adjust 'k' as necessary for your analysis
km <- kproto(subset_data_matrix4, try_clusters)
# Calculate Gower distance
gower_dist <- daisy(subset_data_matrix4, metric = 'gower')
# Calculate silhouette score
silhouette_score <- silhouette(km$cluster, gower_dist)
# Average silhouette width
avg_sil_width <- mean(silhouette_score[, "sil_width"])
print(avg_sil_width)
# Plot the silhouette plot (optional)
fviz_silhouette(silhouette_score)
#dunn index
library(fpc)
dunn_index <- cluster.stats(gower_dist, km$cluster)$dunn
print(dunn_index)
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix5), 3)
# Perform k-proto clustering on the cleaned matrix
# Adjust 'k' as necessary for your analysis
km <- kproto(subset_data_matrix5, try_clusters)
# Calculate Gower distance
gower_dist <- daisy(subset_data_matrix5, metric = 'gower')
# Calculate silhouette score
silhouette_score <- silhouette(km$cluster, gower_dist)
# Average silhouette width
avg_sil_width <- mean(silhouette_score[, "sil_width"])
print(avg_sil_width)
# Plot the silhouette plot (optional)
fviz_silhouette(silhouette_score)
#dunn index
library(fpc)
dunn_index <- cluster.stats(gower_dist, km$cluster)$dunn
print(dunn_index)
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix6), 8)
# Perform k-proto clustering on the cleaned matrix
# Adjust 'k' as necessary for your analysis
km <- kproto(subset_data_matrix6, try_clusters)
# Calculate Gower distance
gower_dist <- daisy(subset_data_matrix6, metric = 'gower')
# Calculate silhouette score
silhouette_score <- silhouette(km$cluster, gower_dist)
# Average silhouette width
avg_sil_width <- mean(silhouette_score[, "sil_width"])
print(avg_sil_width)
# Plot the silhouette plot (optional)
fviz_silhouette(silhouette_score)
#dunn index
library(fpc)
dunn_index <- cluster.stats(gower_dist, km$cluster)$dunn
print(dunn_index)
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix7), 4)
# Perform k-proto clustering on the cleaned matrix
# Adjust 'k' as necessary for your analysis
km <- kproto(subset_data_matrix7, try_clusters)
# Calculate Gower distance
gower_dist <- daisy(subset_data_matrix7, metric = 'gower')
# Calculate silhouette score
silhouette_score <- silhouette(km$cluster, gower_dist)
# Average silhouette width
avg_sil_width <- mean(silhouette_score[, "sil_width"])
print(avg_sil_width)
# Plot the silhouette plot (optional)
fviz_silhouette(silhouette_score)
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix7), 4)
# Perform k-proto clustering on the cleaned matrix
# Adjust 'k' as necessary for your analysis
km <- kproto(subset_data_matrix7, try_clusters)
# Calculate Gower distance
gower_dist <- daisy(subset_data_matrix7, metric = 'gower')
# Calculate silhouette score
silhouette_score <- silhouette(km$cluster, gower_dist)
# Average silhouette width
avg_sil_width <- mean(silhouette_score[, "sil_width"])
print(avg_sil_width)
# Plot the silhouette plot (optional)
fviz_silhouette(silhouette_score)
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix8), 8)
# Perform k-proto clustering on the cleaned matrix
# Adjust 'k' as necessary for your analysis
km <- kproto(subset_data_matrix8, try_clusters)
# Calculate Gower distance
gower_dist <- daisy(subset_data_matrix8, metric = 'gower')
# Calculate silhouette score
silhouette_score <- silhouette(km$cluster, gower_dist)
# Average silhouette width
avg_sil_width <- mean(silhouette_score[, "sil_width"])
print(avg_sil_width)
# Plot the silhouette plot (optional)
fviz_silhouette(silhouette_score)
#dunn index
library(fpc)
dunn_index <- cluster.stats(gower_dist, km$cluster)$dunn
print(dunn_index)
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix9), 4)
# Perform k-proto clustering on the cleaned matrix
# Adjust 'k' as necessary for your analysis
km <- kproto(subset_data_matrix9, try_clusters)
# Calculate Gower distance
gower_dist <- daisy(subset_data_matrix9, metric = 'gower')
# Calculate silhouette score
silhouette_score <- silhouette(km$cluster, gower_dist)
# Average silhouette width
avg_sil_width <- mean(silhouette_score[, "sil_width"])
print(avg_sil_width)
# Plot the silhouette plot (optional)
fviz_silhouette(silhouette_score)
#dunn index
library(fpc)
dunn_index <- cluster.stats(gower_dist, km$cluster)$dunn
print(dunn_index)
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix10), 3)
# Perform k-proto clustering on the cleaned matrix
# Adjust 'k' as necessary for your analysis
km <- kproto(subset_data_matrix10, try_clusters)
# Calculate Gower distance
gower_dist <- daisy(subset_data_matrix10, metric = 'gower')
# Calculate silhouette score
silhouette_score <- silhouette(km$cluster, gower_dist)
# Average silhouette width
avg_sil_width <- mean(silhouette_score[, "sil_width"])
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix10), 3)
# Perform k-proto clustering on the cleaned matrix
# Adjust 'k' as necessary for your analysis
km <- kproto(subset_data_matrix10, try_clusters)
####################
####Dataset single##
####################
#Check is NA value in sub_data4
any(is.na(single))
# we want to know how many level does categorical variable status have.
# Get unique values of STATUS if it's not a factor
unique_values <- unique(single$STATUS)
# Print the unique values
print(unique_values)
# Print the number of unique values
print(paste("Number of unique values in STATUS:", length(unique_values)))
#so total should have 3 cluster
#Return False means no missing value
#remove the "" value in the cells
single <- single[single$OCCUPATION_TYPE != "", ]
#married<-married %>% select(-ID, -NAME_FAMILY_STATUS,-STATUS)
library(dplyr)
# Check if all columns exist
if (all(c("ID", "NAME_FAMILY_STATUS", "STATUS") %in% colnames(single))) {
# If all columns exist, remove them using dplyr's select
single <- dplyr::select(single, -ID, -NAME_FAMILY_STATUS, -STATUS)
} else {
# If not all columns exist, take an alternative action
print("One or more specified columns do not exist in the dataframe.")
}
data_matrix10 <- as.data.frame(single)
#Step 3: Extract the significant variable
# Assuming data_matrix9 is your dataset
column_lengths <- sapply(data_matrix10, length)
# View the lengths
print(column_lengths)
# Check if all columns have the same length
all_equal <- all(column_lengths == column_lengths[1])
if (all_equal) {
print("All columns have the same length.")
} else {
print("Not all columns have the same length.")
}
# Assuming data_matrix1 is already loaded in your R environment
library(FactoMineR)
# Performing FAMD
famd_result <- FAMD(data_matrix10, graph = FALSE)
# Selecting top contributing variables for the first ten principal component
top_variables_dim2 <- sort(famd_result$var$contrib[, "Dim.1"], decreasing = TRUE)[1:10]
# for the first ten principal component name
top_var_df3 <- as.data.frame(top_variables_dim2)
top_var_df3$Variable <- rownames(top_var_df3)
subset_data_matrix10 <- data_matrix10[, top_var_df3$Variable]
#View(subset_data_matrix10)
# Recalculate the distance matrix
library(gower)
# Convert character columns to factors or numerics
if (exists("subset_data_matrix10")) {
for (col in colnames(subset_data_matrix10)) {
if (is.character(subset_data_matrix10[[col]])) {
subset_data_matrix10[[col]] <- as.factor(subset_data_matrix10[[col]])
}
}
} else {
print("subset_data_matrix9 is not a valid data frame.")
}
dist_matrix = daisy(subset_data_matrix10,metric = 'gower')
# Hierarchical clustering
hc <- hclust(dist_matrix, method = "complete")  # You can try different methods like "average", "single", etc.
print(hc)
plot(hc)
# Cutting the dendrogram to form clusters
cutree_hc <- cutree(hc, k = 3) # for example, 3 clusters
# Silhouette analysis
silhouette_score <- silhouette(cutree_hc, daisy(subset_data_matrix10,metric = 'gower'))
plot(silhouette_score,col="blue")
#cophenetic
copheneticA<-cophenetic(hc)
cor(copheneticA,dist_matrix)
#using wss
fviz_nbclust(subset_data_matrix10,hcut,method = c("wss"))
#using silhouette
fviz_nbclust(subset_data_matrix10,hcut,method = c("silhouette"))
#dunn index
library(fpc)
dunn_index <- cluster.stats(dist_matrix, cutree_hc)$dunn
print(dunn_index)
#transfrom variable
subset_data_matrix10[["CNT_CHILDREN"]] <- as.factor(subset_data_matrix10[["CNT_CHILDREN"]])
subset_data_matrix10[["FLAG_MOBIL"]] <- as.factor(subset_data_matrix10[["FLAG_MOBIL"]])
subset_data_matrix10[["FLAG_WORK_PHONE"]] <- as.factor(subset_data_matrix10[["FLAG_WORK_PHONE"]])
subset_data_matrix10[["FLAG_PHONE"]] <- as.factor(subset_data_matrix10[["FLAG_PHONE"]])
subset_data_matrix10[["FLAG_EMAIL"]] <- as.factor(subset_data_matrix10[["FLAG_EMAIL"]])
subset_data_matrix10[["CNT_FAM_MEMBERS"]] <- as.factor(subset_data_matrix10[["CNT_FAM_MEMBERS"]])
#kprototype
library(klaR)
library(clustMixType)
library(factoextra)
# Set the number of clusters, ensuring it does not exceed the number of rows
try_clusters <- min(nrow(subset_data_matrix10), 3)
# Perform k-proto clustering on the cleaned matrix
# Adjust 'k' as necessary for your analysis
km <- kproto(subset_data_matrix10, try_clusters)
# Calculate Gower distance
gower_dist <- daisy(subset_data_matrix10, metric = 'gower')
# Calculate silhouette score
silhouette_score <- silhouette(km$cluster, gower_dist)
# Average silhouette width
avg_sil_width <- mean(silhouette_score[, "sil_width"])
print(avg_sil_width)
# Plot the silhouette plot (optional)
fviz_silhouette(silhouette_score)
#dunn index
library(fpc)
dunn_index <- cluster.stats(gower_dist, km$cluster)$dunn
print(dunn_index)
########################################
### Dataset highschool####
########################################
# Step 2: Data Preparation
#Check is NA value in sub_data1
any(is.na(highschool))
# we want to know how many level does categorical variable status have.
# Get unique values of STATUS if it's not a factor
unique_values <- unique(highschool$STATUS)
# Print the unique values
print(unique_values)
# Print the number of unique values
print(paste("Number of unique values in STATUS:", length(unique_values)))
